{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Code\n",
    "### Retrieve Site and Parse HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"--incognito\")\n",
    "options.add_argument(\"--nogpu\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1280,1280\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--enable-javascript\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": userAgent})\n",
    "\n",
    "driver.get('https://mykbostats.com/players/2001')\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Name and Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = soup.title.text\n",
    "player = t[:t.find(' KBO')]\n",
    "#role = [n['name'] for n in soup.find_all('tbody', class_='syncscroll', limit=2)]\n",
    "\n",
    "teams = {'Doosan': 'Doosan Bears', \n",
    "         'Hanwha': 'Hanwha Eagles', \n",
    "         'Kia': 'Kia Tigers', \n",
    "         'Kiwoom': 'Kiwoom Heroes', \n",
    "         'KT': 'KT Wiz', \n",
    "         'LG': 'LG Twins', \n",
    "         'Lotte': 'Lotte Giants', \n",
    "         'NC': 'NC Dinos', \n",
    "         'Samsung': 'Samsung Lions', \n",
    "         'SSG': 'SSG Landers'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace header with this\n",
    "#might also be good for checking role of player\n",
    "\n",
    "header={\"Pitcher\":None, \"Batter\":None}\n",
    "\n",
    "for h in soup.find_all('thead'):\n",
    "  match h['name'] :\n",
    "    case 'pitching':\n",
    "      header['Pitcher'] = (h.get_text().split())\n",
    "    case 'batting':\n",
    "      header['Batter'] = (h.get_text().split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Table Contents \n",
    "Write to contents to dataframe, then write to CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unicodedata import numeric\n",
    "\n",
    "\n",
    "#to handle unicode data in table\n",
    "def uni_to_num (unicode):\n",
    "    if ('(' in unicode):\n",
    "       return unicode\n",
    "    elif len(unicode) == 0:\n",
    "        return None\n",
    "    elif len(unicode) == 1:\n",
    "        num = numeric(unicode)\n",
    "    elif unicode[-1].isdigit():\n",
    "        # normal number, ending in [0-9]\n",
    "        num = float(unicode)\n",
    "    else:\n",
    "        # Assume the last character is a vulgar fraction\n",
    "        num = float(unicode[:-1]) + numeric(unicode[-1])\n",
    "    return num\n",
    "\n",
    "pitchdata = None\n",
    "batdata = None\n",
    "\n",
    "pitchtemp = []\n",
    "battemp = []\n",
    "\n",
    "# go through all the tables in the page\n",
    "for r in soup.find_all('table'):\n",
    "  # ignore the pitching-games and batting-games tables\n",
    "  if ('games' in r.thead['name']):\n",
    "    break  \n",
    "\n",
    "  # Go through the table bodies\n",
    "  for tb in r.select('tbody tr'):\n",
    "    # skip the empty or career tables\n",
    "    if (tb.select_one('.left') == None or tb.select_one('.left').text.strip() == 'Career'):\n",
    "      continue\n",
    "\n",
    "    #Extracting table information\n",
    "    # make temp list for each row, init with player name, and first two column entries\n",
    "    t = [player, tb.select('td')[0].text, tb.select('td')[1].text.strip()]\n",
    "    # go through rest of the row\n",
    "    for i in tb.select('td')[2:]:\n",
    "      if (i.text == ''):\n",
    "        t.append(None)\n",
    "      else:\n",
    "        t.append(uni_to_num(i.text.strip()))\n",
    "\n",
    "    # sort data accordingly\n",
    "    if (r.thead['name'] == 'pitching'):\n",
    "      pitchtemp.append(t)\n",
    "    if (r.thead['name']=='batting'):\n",
    "      battemp.append(t)\n",
    "\n",
    "  # make dataframes\n",
    "  headers = ['Name'] + r.thead.get_text().split()\n",
    "  if (r.thead['name']=='pitching'):\n",
    "     pitchdata = pd.DataFrame(data=pitchtemp, columns=headers)\n",
    "  if (r.thead['name']=='batting'):\n",
    "     batdata = pd.DataFrame(data=battemp, columns=headers)\n",
    "\n",
    "\n",
    "\n",
    "print(pitchdata)\n",
    "print(batdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (133.0.6943.141) detected in PATH at chromedriver.EXE might not be compatible with the detected chrome version (134.0.6998.35); currently, chromedriver 134.0.6998.35 is recommended for chrome 134.*, so it is advised to delete the driver in PATH and retry\n",
      "The chromedriver version (133.0.6943.141) detected in PATH at chromedriver.EXE might not be compatible with the detected chrome version (134.0.6998.35); currently, chromedriver 134.0.6998.35 is recommended for chrome 134.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "#%pip install ...\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import numeric\n",
    "from time import sleep\n",
    "\n",
    "def uni_to_num (unicode):\n",
    "    '''\n",
    "    Given string of unicode, convert into numerics.\n",
    "    '''\n",
    "    \n",
    "    if ('(' in unicode):\n",
    "       return unicode\n",
    "    elif len(unicode) == 0:\n",
    "        return None\n",
    "    elif len(unicode) == 1:\n",
    "        num = numeric(unicode)\n",
    "    elif unicode[-1].isdigit():\n",
    "        # normal number, ending in [0-9]\n",
    "        num = float(unicode)\n",
    "    else:\n",
    "        # Assume the last character is a vulgar fraction\n",
    "        num = float(unicode[:-1]) + numeric(unicode[-1])\n",
    "\n",
    "    return num\n",
    "\n",
    "\n",
    "def get_player (soup):\n",
    "    '''\n",
    "    Given BeautifulSoup object with HTML code, return player name \n",
    "    '''\n",
    "    \n",
    "    t = soup.title.text\n",
    "    return t[:t.find(' KBO')]\n",
    "    \n",
    "\n",
    "\n",
    "def get_website (url):\n",
    "    '''\n",
    "    Given string containing url of website, return BeautifulSoup object with parsed HTML code\n",
    "    '''\n",
    "\n",
    "    # Make sure to have ChromeDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument(\"--nogpu\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--window-size=1280,1280\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": userAgent})\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    return BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "def fix_team_names (df):\n",
    "    '''\n",
    "    Given dataframe with player information, adjust Team names column to represent the full team name\n",
    "    '''\n",
    "    teams = {'Doosan': 'Doosan Bears', \n",
    "            'Hanwha': 'Hanwha Eagles', \n",
    "            'Kia': 'Kia Tigers', \n",
    "            'Kiwoom': 'Kiwoom Heroes', \n",
    "            'KT': 'KT Wiz', \n",
    "            'LG': 'LG Twins', \n",
    "            'Lotte': 'Lotte Giants', \n",
    "            'NC': 'NC Dinos', \n",
    "            'Samsung': 'Samsung Lions', \n",
    "            'SSG': 'SSG Landers'}\n",
    "    \n",
    "    for i in df.index:\n",
    "        df.loc[i, 'Team'] = teams[df.loc[i, 'Team']]\n",
    "\n",
    "\n",
    "\n",
    "#count which pages have been scraped\n",
    "count = 0\n",
    "\n",
    "for i in range(2000,2002):\n",
    "    pitchdata = None\n",
    "    batdata = None\n",
    "\n",
    "    pitchtemp = []\n",
    "    battemp = []\n",
    "    \n",
    "    url = \"https://mykbostats.com/players/\" + str(i)\n",
    "    soup = get_website(url)\n",
    "\n",
    "    player = get_player(soup)\n",
    "\n",
    "    # go through all the tables in the page\n",
    "    for r in soup.find_all('table'):\n",
    "        #ignore the pitching-games and batting-games tables\n",
    "        if ('games' in r.thead['name']):\n",
    "           break  \n",
    "\n",
    "        # Go through the table bodies\n",
    "        for tb in r.select('tbody tr'):\n",
    "            # skip the empty or career tables\n",
    "            if (tb.select_one('.left') == None or tb.select_one('.left').text.strip() == 'Career'):\n",
    "               continue\n",
    "           \n",
    "            #Extracting table information\n",
    "            # make temp list for each row, init with player name, and first two column entries\n",
    "            t = [player, tb.select('td')[0].text, tb.select('td')[1].text.strip()]\n",
    "            # go through rest of the row\n",
    "            for q in tb.select('td')[2:]:\n",
    "                if (q.text == ''):\n",
    "                    t.append(None)\n",
    "                else:\n",
    "                    t.append(uni_to_num(q.text.strip()))\n",
    "                \n",
    "                # sort data accordingly\n",
    "            if (r.thead['name'] == 'pitching'):\n",
    "                pitchtemp.append(t)\n",
    "            if (r.thead['name']=='batting'):\n",
    "                battemp.append(t)\n",
    "            \n",
    "        # make dataframes\n",
    "        headers = ['Name'] + r.thead.get_text().split()\n",
    "        if (r.thead['name']=='pitching'):\n",
    "            pitchdata = pd.DataFrame(data=pitchtemp, columns=headers)\n",
    "            fix_team_names(pitchdata)\n",
    "            pitchdata.to_csv('KBO_Pitchers.csv', header=(i <= 2), index=False, mode='a')\n",
    "\n",
    "        if (r.thead['name']=='batting'):\n",
    "            batdata = pd.DataFrame(data=battemp, columns=headers)\n",
    "            fix_team_names(batdata)\n",
    "            batdata.to_csv('KBO_Batters.csv', header=(i <= 2), index=False, mode='a')\n",
    "    \n",
    "    # header will be included in csv only during initialization\n",
    "    # first two pages should be pitcher and batter, respectively\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    sleep(5) #website crawl-delay\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

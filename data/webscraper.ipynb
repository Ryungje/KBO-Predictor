{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Site and Parse HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"--incognito\")\n",
    "options.add_argument(\"--nogpu\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1280,1280\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--enable-javascript\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": userAgent})\n",
    "\n",
    "driver.get('https://mykbostats.com/players/1')\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Name and Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = soup.select('title')[0].text.strip()\n",
    "player = t[:t.find(' - ')]\n",
    "\n",
    "teams = {'Doosan': 'Doosan Bears', \n",
    "         'Hanwha': 'Hanwha Eagles', \n",
    "         'Kia': 'Kia Tigers', \n",
    "         'Kiwoom': 'Kiwoom Heroes', \n",
    "         'KT': 'KT Wiz', \n",
    "         'LG': 'LG Twins', \n",
    "         'Lotte': 'Lotte Giants', \n",
    "         'NC': 'NC Dinos', \n",
    "         'Samsung': 'Samsung Lions', \n",
    "         'SSG': 'SSG Landers'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract table header information\n",
    "header = soup.select('thead th')\n",
    "for i in range(len(header)):\n",
    "  header[i] = header[i].text.strip()\n",
    "\n",
    "# remove 'Game Stats' data\n",
    "header = header[:header.index(\"Date\")]\n",
    "header = ['Name'] + header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Table Contents \n",
    "Write to contents to dataframe, then write to CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "import pandas as pd\n",
    "from unicodedata import numeric\n",
    "\n",
    "\n",
    "#to handle unicode data in table\n",
    "def uni_to_num (unicode):\n",
    "    if ('(' in unicode):\n",
    "       return unicode\n",
    "    elif len(unicode) == 0:\n",
    "        return None\n",
    "    elif len(unicode) == 1:\n",
    "        num = numeric(unicode)\n",
    "    elif unicode[-1].isdigit():\n",
    "        # normal number, ending in [0-9]\n",
    "        num = float(unicode)\n",
    "    else:\n",
    "        # Assume the last character is a vulgar fraction\n",
    "        num = float(unicode[:-1]) + numeric(unicode[-1])\n",
    "    return num\n",
    "\n",
    "\n",
    "#data to be inserted into dataframe later\n",
    "temp = []\n",
    "\n",
    "# Parse row data and add to temp\n",
    "rows = soup.select('tbody tr')\n",
    "\n",
    "for r in rows:\n",
    "  if (r.select_one('.left').text.strip() == 'Career'):\n",
    "    break\n",
    "\n",
    "  t = [player, r.select_one('.left').text.strip(), r.select_one('nobr').text.strip()]  \n",
    "  for i in r.select('td')[2:]:\n",
    "    t.append(uni_to_num(i.text.strip()))\n",
    "  temp.append(t)\n",
    "\n",
    "\n",
    "# init dataframe\n",
    "data = pd.DataFrame(data = temp, columns = header)\n",
    "\n",
    "# write to CSV\n",
    "data.to_csv('data.csv')\n",
    "\n",
    "# read CSV\n",
    "#df = pd.read_csv('.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ...\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import numeric\n",
    "from time import sleep\n",
    "\n",
    "def uni_to_num (unicode):\n",
    "    '''\n",
    "    Given string of unicode, convert into numerics.\n",
    "    '''\n",
    "    \n",
    "    if ('(' in unicode):\n",
    "       return unicode\n",
    "    elif len(unicode) == 0:\n",
    "        return None\n",
    "    elif len(unicode) == 1:\n",
    "        num = numeric(unicode)\n",
    "    elif unicode[-1].isdigit():\n",
    "        # normal number, ending in [0-9]\n",
    "        num = float(unicode)\n",
    "    else:\n",
    "        # Assume the last character is a vulgar fraction\n",
    "        num = float(unicode[:-1]) + numeric(unicode[-1])\n",
    "\n",
    "    return num\n",
    "\n",
    "\n",
    "\n",
    "def get_row_data (rows, player, header):\n",
    "    '''\n",
    "    Given HTML code of table with data and tuple containing player name and role, extract data and return as dataframe.\n",
    "    '''\n",
    "    \n",
    "    rows = soup.select('tbody tr')\n",
    "\n",
    "    temp = []\n",
    "    for r in rows:\n",
    "        # break loop to exclude data from Career onwards\n",
    "        if (r.select_one('.left').text.strip() == 'Career'):\n",
    "            break\n",
    "\n",
    "        t = [player[0], r.select_one('.left').text.strip(), r.select_one('nobr').text.strip()]  \n",
    "        for i in r.select('td')[2:]:\n",
    "            t.append(uni_to_num(i.text.strip()))\n",
    "        temp.append(t)\n",
    "\n",
    "    return pd.DataFrame(data = temp, columns = header)\n",
    "\n",
    "\n",
    "\n",
    "def get_header (soup):\n",
    "    '''\n",
    "    Given a BeautifulSoup object of HTML code, extract table heading information as list of strings\n",
    "    '''\n",
    "    \n",
    "    header = soup.select('thead th')\n",
    "    for i in range(len(header)):\n",
    "        header[i] = header[i].text.strip()\n",
    "\n",
    "    # remove 'Game Stats' data\n",
    "    header = header[:header.index(\"Date\")]\n",
    "    \n",
    "    return ['Name'] + header\n",
    "\n",
    "\n",
    "\n",
    "def get_player (soup):\n",
    "    '''\n",
    "    Given BeautifulSoup object with HTML code, return tuple with player name and role (pitcher/batter) \n",
    "    '''\n",
    "    \n",
    "    t = soup.select('title')[0].text.strip()\n",
    "    \n",
    "    name = t[:t.find(' KBO')]\n",
    "    \n",
    "    if (\"Pitching\" in t):\n",
    "        role = \"Pitcher\"\n",
    "    elif (\"Batting\" in t):\n",
    "        role = \"Batter\"\n",
    "    \n",
    "    return (name, role)\n",
    "\n",
    "\n",
    "\n",
    "def get_website (url):\n",
    "    '''\n",
    "    Given string containing url of website, return BeautifulSoup object with parsed HTML code\n",
    "    '''\n",
    "\n",
    "    # generated from ZenRows.com\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument(\"--nogpu\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--window-size=1280,1280\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": userAgent})\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    return BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "def fix_team_names (df):\n",
    "    '''\n",
    "    Given dataframe with player information, adjust Team names column to represent the full team name\n",
    "    '''\n",
    "    teams = {'Doosan': 'Doosan Bears', \n",
    "            'Hanwha': 'Hanwha Eagles', \n",
    "            'Kia': 'Kia Tigers', \n",
    "            'Kiwoom': 'Kiwoom Heroes', \n",
    "            'KT': 'KT Wiz', \n",
    "            'LG': 'LG Twins', \n",
    "            'Lotte': 'Lotte Giants', \n",
    "            'NC': 'NC Dinos', \n",
    "            'Samsung': 'Samsung Lions', \n",
    "            'SSG': 'SSG Landers'}\n",
    "    \n",
    "    for i in df.index:\n",
    "        df.loc[i, 'Team'] = teams[df.loc[i, 'Team']]\n",
    "\n",
    "\n",
    "\n",
    "#count which pages have been scraped\n",
    "count = 0\n",
    "\n",
    "for i in range(1, 4): \n",
    "    \n",
    "    # Use to see if dataframe headers should be written to csv.\n",
    "    # At time of writing, first two pages are pitcher and batter, respectively.\n",
    "    # Use these two to incude header in csv then ignore headers for pages after.\n",
    "    if (i <= 2):\n",
    "        yeshead = True\n",
    "    else:\n",
    "        yeshead = False\n",
    "\n",
    "    url = \"https://mykbostats.com/players/\" + str(i)\n",
    "    soup = get_website(url)\n",
    "    \n",
    "    player = get_player(soup)\n",
    "    header = get_header(soup)\n",
    "    rows = soup.select('tbody tr')\n",
    "    data = get_row_data(rows, player, header)\n",
    "\n",
    "    fix_team_names(data)\n",
    "\n",
    "    if (player[1] == \"Pitcher\"):\n",
    "        data.to_csv('KBO_Pitchers.csv', header=yeshead, mode='a')\n",
    "\n",
    "    if (player[1] == \"Batter\"):\n",
    "        data.to_csv('KBO_Batters.csv', header=yeshead, mode='a')\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    sleep(5) #website crawl-delay\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
